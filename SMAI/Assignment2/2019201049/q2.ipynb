{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## q2   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the libraries\n",
    "#import statistics \n",
    "from statistics import mode \n",
    "import numpy as np;\n",
    "import pandas as pd;\n",
    "from scipy.spatial import distance\n",
    "import math\n",
    "\n",
    "from sklearn.metrics import accuracy_score,recall_score,precision_score,f1_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eucledian Distance  w.r.t  to xtrain and xtest return a single euclidean "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean(a,b):\n",
    "    sum=0\n",
    "    for count,i in enumerate(a):\n",
    "        x= a[count]- b[count]\n",
    "        sum= sum + x*x\n",
    "\n",
    "    res= math.sqrt(sum)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Knn Algorithm\n",
    "* Calculate eucledian distance of w.r.t each row in training dataset and append two list\n",
    "* Created a two dimenssional list which contain label and eucledean distance\n",
    "* Sort that two dimenssional array\n",
    "* Took first K smallest distances from the list\n",
    "* Find the maximum occurence of distance in list of K element.\n",
    "* Append the label of that distance into res list.\n",
    "* Return res which contain Predicted Labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_classifier(x,y_train,xtest,k):\n",
    "    res=[]\n",
    "    for rowtest in xtest:\n",
    "        c1=0\n",
    "        pnt2=[i for i in rowtest]\n",
    "        l=[]\n",
    "        for row in x:\n",
    "            \n",
    "            pnt1= [i for i in row]\n",
    "            twodim=[]\n",
    "            dist=euclidean(pnt1,pnt2)\n",
    "            twodim.append(dist)\n",
    "            twodim.append(c1)\n",
    "            c1=c1+1\n",
    "            l.append(twodim)\t\n",
    "        l.sort()    #[[dist,index],[..],[..]]\n",
    "        classes= set(y_train)\n",
    "        d={}\n",
    "        for c in classes:\n",
    "            d[c]=0\n",
    "        for i in range(k):\n",
    "            ind= l[i][1]\n",
    "            label = y_train[ind]\n",
    "            d[label] = d[label]+1\n",
    "        maxv=0\n",
    "        for i in d:\n",
    "            if(d[i]>maxv):\n",
    "                maxv=d[i]\n",
    "                key=i\n",
    "        res.append(key)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Major task in this dataset is to handle value \"?\"\n",
    "1. For this purpose we used replace function which can repace character in dataset and Fillna Function which used to fill NaN valuess in dataset\n",
    "2.  We use ascii value to convert catagorical data to numerical data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     k    s    n    f  n.1    a    c    b    y  e.1  ...  s.1  s.2    o  o.1  \\\n",
      "0  107  115  103  102  110  102  119   98  112  101  ...  115  115  119  119   \n",
      "1   98  115  103  102  110  102  119   98  119  101  ...  115  115  119  119   \n",
      "2  115  102  103  102  110  102   99  110  110  101  ...  115  115  119  119   \n",
      "3  102  102  103  102  110  102  119   98  112  116  ...  115  102  119  119   \n",
      "4  120  115  110  102  110  102  119   98  104  116  ...  115  102  119  119   \n",
      "\n",
      "     p  n.2  o.2  p.1  b.1  c.1  \n",
      "0  112  119  116  112  119  115  \n",
      "1  112  119  116  112  119  115  \n",
      "2  112  119  111  112  110  118  \n",
      "3  112  119  111  101  110   97  \n",
      "4  112  119  111  101  107   97  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('/home/gsmodi/2SMAI/Assignment1 Dataset/Datasets/q2/train.csv')\n",
    "y = dataset.iloc[:, 0].values             #dependent variables\n",
    "dataset=dataset.replace('?',np.NaN)\n",
    "dataset['?'].fillna(dataset['?'].mode()[0],inplace=True)\n",
    "# Splitting the dataset into the Training set and Validation set\n",
    "\n",
    "rows=len(dataset.index)\n",
    "for r in range (0,rows):\n",
    "    for row,col in enumerate(dataset):\n",
    "        dataset.iloc[r][col]=ord(dataset.iloc[r][col])\n",
    "x=dataset.iloc[:,1:22]\n",
    "print(x.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25)\n",
    "y_test=y_test.tolist()\n",
    "\n",
    "y_train=y_train.tolist()\n",
    "x_train=x_train.values.tolist()\n",
    "x_test=x_test.values.tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### matrix in output is confusion matrix\n",
    "## For different K's we print Confusion Matrix ----Accuracy----Recall---Precision----F1score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[395   3]\n",
      " [  2 724]]\n",
      "0.9955516014234875\n",
      "0.9972451790633609\n",
      "0.9958734525447043\n",
      "0.9965588437715072\n"
     ]
    }
   ],
   "source": [
    "# Fitting K-NN to the Training set and # Predicting the Test set results\n",
    "\n",
    "y_pred=knn_classifier(x_train,y_train,x_test,11)\n",
    "\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(recall_score(y_test,y_pred,pos_label='p'))\n",
    "print(precision_score(y_test,y_pred,pos_label='p'))\n",
    "print(f1_score(y_test,y_pred,pos_label='p'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[395   3]\n",
      " [  2 724]]\n",
      "0.9955516014234875\n",
      "0.9972451790633609\n",
      "0.9958734525447043\n",
      "0.9965588437715072\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred=knn_classifier(x_train,y_train,x_test,9)\n",
    "\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(recall_score(y_test,y_pred,pos_label='p'))\n",
    "print(precision_score(y_test,y_pred,pos_label='p'))\n",
    "print(f1_score(y_test,y_pred,pos_label='p'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[395   3]\n",
      " [  2 724]]\n",
      "0.9955516014234875\n",
      "0.9972451790633609\n",
      "0.9958734525447043\n",
      "0.9965588437715072\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred=knn_classifier(x_train,y_train,x_test,7)\n",
    "\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(recall_score(y_test,y_pred,pos_label='p'))\n",
    "print(precision_score(y_test,y_pred,pos_label='p'))\n",
    "print(f1_score(y_test,y_pred,pos_label='p'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## we calculated same confusion matrix and accuracy with help of sklearn library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[395   3]\n",
      " [  2 724]]\n",
      "0.9955516014234875\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import numpy as np\n",
    "\n",
    "neigh = KNeighborsClassifier(n_neighbors=7)\n",
    "neigh.fit(x_train, y_train)\n",
    "p = neigh.predict(x_test)\n",
    "print (confusion_matrix(y_test,p))\n",
    "print (accuracy_score(y_test,p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation\n",
    "    1. Changes in K value affects accuracy but percentage of affection is very less"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RESULT\n",
    "    1. We get nearly same accuracy as sklearn library Knnclassifier for given value of k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
